{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#from osgeo import gdal # Import the GDAL library\n",
    "import sys,getopt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import numpy.core.multiarray \n",
    "import netCDF4 as nc4\n",
    "import xarray as xr\n",
    "import scipy.interpolate\n",
    "import requests\n",
    "import cdsapi\n",
    "import glob\n",
    "from cfgrib import xarray_to_grib\n",
    "import os\n",
    "import cfgrib\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib as mpl\n",
    "from PIL import Image\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = pl.Path('/Users/tmiesse/work/libraries/adcirc-unswan')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Keys for GFS grib reanalsis:\n",
    "u-component_of_wind_height_above_ground\n",
    "v-component_of_wind_height_above_ground\n",
    "Pressure_surface\n",
    "160 -> 240\n",
    "87 -> 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = np.arange(8,29).astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 12:42:33,679 INFO Welcome to the CDS\n",
      "2022-02-09 12:42:33,680 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2022-02-09 12:42:34,211 INFO Request is queued\n",
      "2022-02-09 13:09:01,146 INFO Request is running\n",
      "2022-02-09 13:11:01,624 INFO Request is completed\n",
      "2022-02-09 13:11:01,624 INFO Downloading https://download-0006.copernicus-climate.eu/cache-compute-0006/cache/data5/adaptor.mars.internal-1644430114.205365-4512-12-a48183d7-91f8-400c-ab66-ebef2e9ac947.grib to file2.grib (2.9G)\n",
      "2022-02-09 13:36:42,734 INFO Download rate 1.9M/s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(content_length=3139819200,content_type=application/x-grib,location=https://download-0006.copernicus-climate.eu/cache-compute-0006/cache/data5/adaptor.mars.internal-1644430114.205365-4512-12-a48183d7-91f8-400c-ab66-ebef2e9ac947.grib)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = cdsapi.Client()\n",
    "time = ['00:00', '01:00', '02:00','03:00', '04:00', '05:00',\n",
    "        '06:00', '07:00', '08:00','09:00', '10:00', '11:00',\n",
    "        '12:00', '13:00', '14:00','15:00', '16:00', '17:00',\n",
    "        '18:00', '19:00', '20:00','21:00', '22:00', '23:00',]\n",
    "#days = ['19','20','21','22','23','24','25','26','27'\n",
    "#        ]        #,'03','04','05','06','07','08','09','10','11','12','13','14''18','19','20','21','22','23','24','25','26','27','28','29','30'\n",
    "        \n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels',\n",
    "    {\n",
    "        'product_type': 'reanalysis',\n",
    "        'format': 'grib',\n",
    "        'variable': [\n",
    "            '10m_u_component_of_wind', '10m_v_component_of_wind', 'mean_sea_level_pressure',\n",
    "        ],\n",
    "        'year': '2019',\n",
    "        'month': '11',\n",
    "        'day': days,\n",
    "\n",
    "        'time': time,\n",
    "    },\n",
    "    'file2.grib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-09 13:47:18,076 WARNING Ignoring index file '/Users/tmiesse/work/libraries/adcirc-unswan/inputs/file2.grib.4cc40.idx' older than GRIB file\n",
      "2022-02-09 13:47:22,636 INFO missing from GRIB stream: 'directionNumber'\n",
      "2022-02-09 13:47:22,636 INFO missing from GRIB stream: 'frequencyNumber'\n",
      "2022-02-09 13:47:22,850 INFO missing from GRIB stream: 'directionNumber'\n",
      "2022-02-09 13:47:22,850 INFO missing from GRIB stream: 'frequencyNumber'\n",
      "2022-02-09 13:47:23,056 INFO missing from GRIB stream: 'directionNumber'\n",
      "2022-02-09 13:47:23,057 INFO missing from GRIB stream: 'frequencyNumber'\n"
     ]
    }
   ],
   "source": [
    "path = pl.Path('/Users/tmiesse/work/libraries/adcirc-unswan/inputs')\n",
    "file = 'file2.grib'\n",
    "grib = xr.open_dataset(path  / file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "path = pl.Path('/Users/tmiesse/Downloads')\n",
    "file = 'wnd10m.gdas.201111.grib2'\n",
    "grib = xr.open_dataset(path  / file, engine='cfgrib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = grib.data_vars['u10'].values[:,:,:]\n",
    "v = grib.data_vars['v10'].values[:,:,:]\n",
    "\n",
    "time = grib.coords['time'].values[:]\n",
    "#step = grib.coords['step'].values[:]\n",
    "lat = grib.coords['latitude'].values\n",
    "lon = grib.coords['longitude'].values#-360\n",
    "\n",
    "# if you want to split the time\n",
    "#start = '2011-11-01 00:00:00'\n",
    "#end = '2011-11-20 00:00:00'\n",
    "#start_split = np.where(((pd.to_datetime(start)-pd.Timedelta(hours=1))<pd.to_datetime(time))&(pd.to_datetime(time)<=(pd.to_datetime(start)+pd.Timedelta(hours=1))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grib.coords['longitude'] = grib.coords['longitude'][:]-360\n",
    "#grib.to_netcdf(path / 'fort.222.nc',format='NETCDF4')#, grib_keys={grib.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = 'prmsl.gdas.201911.grib2'\n",
    "grib2 = xr.open_dataset(path  / file, engine='cfgrib')\n",
    "grib2.coords['longitude'] = grib2.coords['longitude'].values-360\n",
    "#grib2.to_netcdf(path / 'fort.221.nc',format='NETCDF4')#, grib_keys={grib.keys()})\n",
    "grib2 = grib2.interp(latitude=lat,longitude=lon,method='nearest')#.data_vars['prmsl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lats2 = np.arange(90,-90.205,-0.205)\n",
    "lons2 = np.arange(0,360.205,0.205)\n",
    "path = pl.Path('/Users/tmiesse/Downloads')\n",
    "file = 'prmsl.gdas.201111.grib2'\n",
    "grib2 = xr.open_dataset(path  / file, engine='cfgrib')\n",
    "#grib2.coords['longitude'] = grib2.coords['longitude'].values-360\n",
    "#grib.to_netcdf(path / 'fort.221.nc',format='NETCDF4')#, grib_keys={grib.keys()})\n",
    "\n",
    "#grib2.to_netcdf(path / 'fort.221.nc',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-12-a64a820ed0a8>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-a64a820ed0a8>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for t in range(len(time)):\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "u2 = np.array((120,len(lat),len(lon)))\n",
    "v2 = np.array((120,len(lat),len(lon)))\n",
    "for t in range(len(time)):\n",
    "    u2[t,:,:] = grib.data_vars['u10'].values[t,1,:,:]\n",
    "    v2[t,:,:] = grib.data_vars['v10'].values[t,1,:,:]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lats,lons = grib.coords['latitude'][:],grib.coords['longitude'][:]\n",
    "lats2,lons2 = grib2.coords['latitude'][:],grib2.coords['longitude'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = nc4.Dataset(path/'fort.222.nc','w')\n",
    "time2 = file.createDimension('time',120)\n",
    "lat2 = file.createDimension('lat',len(lat))\n",
    "lon2 = file.createDimension('lon',len(lon))\n",
    "file.createVariable('time', 'f4', ('time',))\n",
    "file.createVariable('lat', 'f4', ('lat',))\n",
    "file.createVariable('lon', 'f4', ('lon',))\n",
    "uvalue = file.createVariable('UGRD', 'f4', ('time', 'lat', 'lon',))\n",
    "vvalue = file.createVariable('VGRD', 'f4', ('time', 'lat', 'lon',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in range(0,len(time)):\n",
    "    uvalue[t,:,:] = grib.data_vars['u10'].values[t,1,:,:]\n",
    "    vvalue[t,:,:] = grib.data_vars['v10'].values[t,1,:,:]\n",
    "file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = nc4.Dataset(path/'fort.221.nc','w')\n",
    "time2 = file.createDimension('time',120)\n",
    "lat2 = file.createDimension('lat',len(lat))\n",
    "lon2 = file.createDimension('lon',len(lon))\n",
    "file.createVariable('time', 'f4', ('time',))\n",
    "file.createVariable('lat', 'f4', ('lat',))\n",
    "file.createVariable('lon', 'f4', ('lon',))\n",
    "pvalue = file.createVariable('PRMSL', 'f4', ('time', 'lat', 'lon',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in range(0,len(time)):\n",
    "    pvalue[t,:,:] = grib2.data_vars['prmsl'].values[t,1,:,:]\n",
    "\n",
    "file.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For CFSv2 monthly reanylisis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 497)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = lat[(lat2>=lat) & (lat>lat1)]\n",
    "temp2 = lon[(lon2+360>=lon) & (lon>lon1+360)]\n",
    "len(temp),len(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prmsl = grib.data_vars['msl'].values[:]\n",
    "\n",
    "lat1,lat2 = 47,86 \n",
    "lon1,lon2 = -222.5,-98.25\n",
    "start ='2019-11-08 00:00'\n",
    "end = '2019-11-27 23:00'\n",
    "# ---- generate adcirc forcing file (fort.22)---------\n",
    "dt = np.where((pd.to_datetime(start)<pd.to_datetime(time)) & (pd.to_datetime(time)<=pd.to_datetime(end)))[0]\n",
    "t1,y,x = u.shape\n",
    "u2,v2,p2 = [],[],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon[0]-lon[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in dt:\n",
    "    #for tt in range(0,t2,1):\n",
    "    for i in range(0,len(lat)):\n",
    "        for ii in range(0,len(lon)):\n",
    "            if (lat2>=lat[i]>lat1) and ((lon2+360)>=lon[ii]>(lon1+360)):\n",
    "                u2.append(np.round(u[t,i,ii],3))\n",
    "                v2.append(np.round(v[t,i,ii],3))\n",
    "                p2.append(np.round(prmsl[t,i,i],3))\n",
    "\n",
    "df = pd.DataFrame({'u':np.round(u2,2),'v':np.round(v2,2),'p':np.round(p2,2)})\n",
    "df.to_csv('/Users/tmiesse/work/FHRL/arctic/model/ice_analysis/storm201911/lucia/fort_v2.22', sep='\\t',index=False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = lat[(lat2>=lat) & (lat>lat1)]\n",
    "temp2 = lon[(lon2>=lon) & (lon>lon1)]\n",
    "len(temp),len(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20454519613417688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon[0]-lon[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "grib2.to_netcdf(path / 'fort.221.nc',format='NETCDF4')#, grib_keys={grib.keys()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = grib.data_vars['u10'].values[:]\n",
    "v = grib.data_vars['v10'].values[:]\n",
    "x = grib.coords['longitude'][:]#-360\n",
    "y = grib.coords['latitude'][:]\n",
    "#x = [data-360 if (data>=0) else data for data in x[:].values]\n",
    "xgrid, ygrid = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmiesse/miniconda3/envs/general/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ts = [(t - np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's')  for t in time]\n",
    "ts2 = [datetime.datetime.utcfromtimestamp(t) for t in ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tmiesse/miniconda3/envs/general/lib/python3.7/site-packages/ipykernel_launcher.py:19: MatplotlibDeprecationWarning: \n",
      "The dedent function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use inspect.cleandoc instead.\n"
     ]
    }
   ],
   "source": [
    "t,s = 20,1\n",
    "lat1,lat2 = 35,90\n",
    "lon1,lon2 =-230, -120.039923\n",
    "\n",
    "cmap = 'jet'\n",
    "#key = keys[6]\n",
    "wl=[]\n",
    "s = 0\n",
    "\n",
    "limits = np.arange(920,1060,5)\n",
    "cmaps = mpl.cm.get_cmap(cmap)  \n",
    "normalize = mpl.colors.Normalize(vmin=min(limits), vmax=max(limits))\n",
    "colors = [cmaps(normalize(value)) for value in limits]\n",
    "for i in range(15,len(time[:40])):\n",
    "    fig,ax = plt.subplots(figsize=(16,16))\n",
    "    #mag = np.sqrt(np.square(u[i,s,:,:])+np.square(v[i,s,:,:]))\n",
    "    prmsl= grib2.data_vars['prmsl'].values[i,s,:,:]/100\n",
    "    m = Basemap(llcrnrlat=lat1,urcrnrlat=lat2,\n",
    "            llcrnrlon=lon1,urcrnrlon=lon2,resolution='h', epsg = 4326,ax=ax)\n",
    "    #m.arcgisimage(service='NatGeo_World_Map',xpixels=720, verbose= False,ax=ax)#service='Canvas/World_Light_Gray_Base',\n",
    "    #m.shadedrelief()\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(0, 100, 10), linewidth=0.01,labels=[1,0,0,0], color='#595959')\n",
    "    m.drawmeridians(np.arange(0, 360, 10), linewidth=0.01, labels=[0,0,0,1],zorder=3)\n",
    "    contour = ax.contourf(xgrid,ygrid,prmsl,vmin=np.min(limits),vmax=np.max(limits),levels=len(limits),cmap=cmap)\n",
    "    ax.quiver(xgrid[::10,::10],ygrid[::10,::10],u[i,s,::10,::10],v[i,s,::10,::10], pivot='mid', scale = 600, color='w')\n",
    "    #cax, _ = mpl.colorbar.make_axes(ax,shrink=0.75)\n",
    "    #cbar = mpl.colorbar.ColorbarBase(cax, cmap=cmap)\n",
    "    contour.set_clim(np.min(limits),np.max(limits))\n",
    "    cbar = plt.colorbar(contour,ax=ax,shrink=0.35)\n",
    "    file_number = '%05d'%i\n",
    "    wl.append('WL{}.png'.format(file_number))\n",
    "    cbar.set_label('Sea level pressure [mbar]',fontsize=12)\n",
    "    cbar.mappable.set_clim(np.min(limits),np.max(limits))\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    #fig.suptitle(f'Ice',x=0.435,y=0.725,fontsize=16)\n",
    "    ax.set_xlabel('\\nDate:{}'.format(ts2[i]),position=(0.5,-1.5))\n",
    "    plt.savefig('WL{}.png'.format(file_number),dpi=400,\n",
    "                        bbox_inches = 'tight', pad_inches = 0.1)\n",
    "    plt.close()\n",
    "images = []\n",
    "for ii in range(0,len(wl)):\n",
    "    frames = Image.open(wl[ii])\n",
    "    images.append(frames)\n",
    "images[0].save('cfs_storm2011.gif',\n",
    "   save_all=True,\n",
    "   append_images=images[1:],\n",
    "   delay=.1,\n",
    "   duration=100,\n",
    "   loop=0)\n",
    "for f in glob.glob('WL*'):\n",
    "    os.remove(f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For ERA 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 160)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lat1,lat2 = -80,20\n",
    "#lon1,lon2 = -82, -0.5\n",
    "\n",
    "prmsl = grib.variables['msl'].values[:,:,:]\n",
    "\n",
    "lat1,lat2 = 7.5,46\n",
    "lon1,lon2 = -100, -60\n",
    "\n",
    "\n",
    "lat = grib.coords['latitude'].values\n",
    "lon= grib.coords['longitude'].values\n",
    "time = np.arange(0,len(grib.coords['time'][:]))\n",
    "\n",
    "\n",
    "temp,y,x = u.shape\n",
    "u2,v2,p2 = [],[],[]\n",
    "datay,datax = [], []\n",
    "for t in time:\n",
    "    for i in range(0,y):\n",
    "        for ii in range(0,x):\n",
    "            if (lat2>=lat[i]>lat1) and ((lon2+360)>=lon[ii]>(lon1+360)):\n",
    "                u2.append(np.round(u[t,i,ii],3))\n",
    "                v2.append(np.round(v[t,i,ii],3))\n",
    "                p2.append(prmsl[t,i,ii])\n",
    "                datay.append(i)\n",
    "                datax.append(ii)\n",
    "\n",
    "df = pd.DataFrame({'u':np.round(u2,2),'v':np.round(v2,2),'p':np.round(p2,2)})\n",
    "df.to_csv('file2.22', sep='\\t',index=False,header = False)  \n",
    "\n",
    "temp = lat[(lat2>=lat) & (lat>lat1)]\n",
    "temp2 = lon[(lon2+360>=lon) & (lon>lon1+360)]\n",
    "len(temp),len(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat[0]-lat[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potentially GFS and GEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'ftp://nomads.ncdc.noaa.gov/GFS/analysis_only/201907/20190701/'\n",
    "\n",
    "day = 1\n",
    "data = {}\n",
    "u_wind,v_wind,psl = [],[],[]\n",
    "name = []\n",
    "for m in range(7,8):\n",
    "    for t in range(1,2):\n",
    "        if t < 10:\n",
    "            t_s = '0'+str(t)\n",
    "        else:\n",
    "            t_s = str(t)\n",
    "        url =  'ftp://nomads.ncdc.noaa.gov/GFS/analysis_only/20190{}/20190{}{}/'.format(str(m),str(m),t_s)\n",
    "\n",
    "        for hour in range(0,1):\n",
    "            if hour==0 or hour==6:\n",
    "                time = '0'+str(hour)\n",
    "            else:\n",
    "                time = str(hour)\n",
    "            \n",
    "            file = 'gfsanl_3_20080{}{}_{}00_000.grb'.format(m,t_s,time)\n",
    "            #print(file)\n",
    "            #name.append(file)\n",
    "            #dataset = gdal.Open(url+file)\n",
    "\n",
    "            #for key in dataset.keys():\n",
    "            #    temp = test.GetRasterBand(dataset[key])\n",
    "            #    data[key] = temp.ReadAsArray()\n",
    "            #    print(key,temp)\n",
    "            '''\n",
    "            for i in range(0,90):\n",
    "                for ii in range(160,245):\n",
    "                    u_wind.append(round(data['u_wind'][i,ii],3))\n",
    "                    v_wind.append(round(data['v_wind'][i,ii],3))\n",
    "                    psl.append(round(data['psl'][i,ii],3))\n",
    "        if t==20 and m==8:\n",
    "            break\n",
    "            '''    \n",
    "#df = pd.DataFrame({'u':u_wind,'v':v_wind,'p':psl})\n",
    "#df.to_csv('fort.22', sep='\\t',index=False,header = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gfsanl_3_20080701_0000_000.grb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
